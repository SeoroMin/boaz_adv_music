{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bert_multilingual_label6.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyNsUIexXikgTJrj2Ue8dn4V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# 모듈, 라이브러리 불러오기"],"metadata":{"id":"skRvI8LZV4Xp"}},{"cell_type":"code","metadata":{"id":"I0Cr-VJpXIfl"},"source":["!pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLUSeVq7XNCG"},"source":["import torch\n","\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import get_linear_schedule_with_warmup\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from keras.preprocessing.sequence import pad_sequences\n","from sklearn.model_selection import train_test_split\n","\n","import pandas as pd\n","import numpy as np\n","import random\n","import time\n","import datetime"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 환경세팅"],"metadata":{"id":"So6mFj-TbZ00"}},{"cell_type":"code","metadata":{"id":"IXLd6Sj9XOgu"},"source":["# 구글드라이브 연동\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vo7Ss0AQXXq0"},"source":["# GPU 확인\n","import os\n","\n","n_devices = torch.cuda.device_count()\n","print(n_devices)\n","\n","for i in range(n_devices):\n","    print(torch.cuda.get_device_name(i))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 준비"],"metadata":{"id":"Me7abiwfbbZ7"}},{"cell_type":"code","metadata":{"id":"5SiMzi5PXeDH"},"source":["# 데이터셋 불러오기\n","import pandas as pd\n","train = pd.read_excel('/content/drive/MyDrive/데캡디/감성대화/Training/train.xlsx')\n","sad = pd.read_csv('/content/drive/MyDrive/데캡디/감성대화/Training/슬픈_all.csv')\n","happy = pd.read_csv('/content/drive/MyDrive/데캡디/감성대화/Training/기쁜_all.csv')\n","unrest = pd.read_csv('/content/drive/MyDrive/데캡디/감성대화/Training/불안_all.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mWzcpQ8kXmH"},"source":["# 데이터 label에 맞게 변환\n","sad['label'] = '슬픔'\n","happy['label'] = '기쁨'\n","unrest['label'] = '불안'\n","\n","# 필요한 column만 추출\n","sad = sad[ ['label', 'content'] ]\n","happy = happy[ ['label', 'content'] ]\n","unrest = unrest[ ['label', 'content'] ]\n","\n","# 예시 출력\n","sad"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.head()"],"metadata":{"id":"5ukNsHpyW8ep"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3NklKXbekxil"},"source":["# 필요한 column만 추출\n","df = train[ ['감정_대분류', '사람문장1'] ]\n","\n","# column 이름 변경\n","df = df.rename(columns={'사람문장1':'content', '감정_대분류':'label'})\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"thP3-RLkk7EL"},"source":["# 데이터 합치기\n","df = pd.concat([df, sad, happy, unrest])\n","\n","# 필요한 감정만 추출\n","df = df[(df['label']==\"기쁨\") | (df['label']==\"슬픔\") | (df['label']==\"불안\") | (df['label']==\"불안 \") | (df['label']==\"기쁨 \")]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b9A8TnZPY__r"},"source":["'''\n","# label encoding\n","df.loc[(df['label'] == \"기쁨\"), 'label'] = 0  #발라드 => 0\n","df.loc[(df['label'] == \"불안\"), 'label'] = 1  #밤 => 0\n","df.loc[(df['label'] == \"당황\"), 'label'] = 2  #슬픈 => 0\n","df.loc[(df['label'] == \"슬픔\"), 'label'] = 3  #발라드 => 0\n","df.loc[(df['label'] == \"분노\"), 'label'] = 4  #밤 => 0\n","df.loc[(df['label'] == \"상처\"), 'label'] = 5  #슬픈 => 0\n","df.loc[(df['label'] == \"불안 \"), 'label'] = 1  #슬픈 => 0\n","df.loc[(df['label'] == \"기쁨 \"), 'label'] = 0  #슬픈 => 0\n","'''\n","# label encoding\n","df.loc[(df['label'] == \"기쁨\"), 'label'] = 0  #발라드 => 0\n","df.loc[(df['label'] == \"불안\"), 'label'] = 1  #밤 => 0\n","df.loc[(df['label'] == \"슬픔\"), 'label'] = 2  #발라드 => 0\n","df.loc[(df['label'] == \"불안 \"), 'label'] = 1  #슬픈 => 0\n","df.loc[(df['label'] == \"기쁨 \"), 'label'] = 0  #슬픈 => 0\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vyuVTCVAaDs7"},"source":["# label type 변경(숫자로)\n","df['label'] = pd.to_numeric(df['label'])\n","df.info()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# BERT 모델 준비"],"metadata":{"id":"wKju8rSgbm0P"}},{"cell_type":"code","metadata":{"id":"iOaHKjxVX_Ic"},"source":["# bert 학습을 위해 CLS 토근과 SEP 토큰 삽입 (CLS -> classification 태스크, SEP -> 문장 구분)\n","document_bert = [\"[CLS] \" + str(s) + \" [SEP]\" for s in df['content']]\n","document_bert[:5]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M771eqDKYAi_"},"source":["# BertTokenizer 사용, 모델은 multilingual 모델\n","tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n","tokenized_texts = [tokenizer.tokenize(s) for s in document_bert]\n","print(tokenized_texts[0])\n","'''\n","from transformers import BertTokenizerFast, EncoderDecoderModel\n","tokenizer = BertTokenizerFast.from_pretrained(\"kykim/bertshared-kor-base\")\n","model = EncoderDecoderModel.from_pretrained(\"kykim/bertshared-kor-base\", num_labels=6)\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FdTXPjITYVuI"},"source":["# MAX_LEN -> padding과 유사한 기법, 문장 길이의 분포를 가지고 많이 나타난 길이를 MAX_LEN으로 설정하면 좋음\n","MAX_LEN = 32\n","# token -> ids(숫자)로 변경\n","input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n","input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')\n","input_ids[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W9sSJKu0YZmv"},"source":["# mask -> softmax 확률 값을 0으로 무기하는 역할, 0이 되면 해당 단어의 정보는 셀프 어텐션에 포함되지 않음\n","attention_masks = []\n","\n","for seq in input_ids:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","    \n","print(attention_masks[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 변환"],"metadata":{"id":"mVlTk9ADbwRh"}},{"cell_type":"code","metadata":{"id":"VCwantIJYbt4"},"source":["# input, label split (8:2)\n","train_inputs, validation_inputs, train_labels, validation_labels = \\\n","train_test_split(input_ids, df['label'].values, random_state=42, test_size=0.2)\n","\n","# mask, ids split (8:2)\n","train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n","                                                       input_ids,\n","                                                       random_state=42, \n","                                                       test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h21p7olDYsl2"},"source":["train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpp4sSlBYoti"},"source":["# 각 값 torch 변환\n","train_inputs = torch.tensor(train_inputs)\n","train_labels = torch.tensor(train_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_inputs = torch.tensor(validation_inputs)\n","validation_labels = torch.tensor(validation_labels)\n","validation_masks = torch.tensor(validation_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y0UhfIACYqng"},"source":["# BATCH_SIZE 조절 (16,32,64,128,256,512)\n","BATCH_SIZE = 32\n","\n","# Data 불러오는 코드 (dataset, sampler, loader)\n","train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n","\n","validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","validation_sampler = SequentialSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8Br75KXbanjQ"},"source":["# gpu 확인\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 최적화 및 하이퍼 파라미터 조정"],"metadata":{"id":"kBsTDqh0b0yu"}},{"cell_type":"code","metadata":{"id":"EHIZW5nDan3c"},"source":["# model 불러오기 (multilingual)\n","model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=3)\n","model.cuda()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZiUn-88pan8v"},"source":["# 옵티마이저 설정\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # 학습률\n","                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값\n","                )\n","\n","# 에폭수\n","epochs = 20\n","\n","# 총 훈련 스텝\n","total_steps = len(train_dataloader) * epochs\n","\n","# lr 조금씩 감소시키는 스케줄러 (나중에는 cosine 실험해볼 예정)\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0,\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 모델 학습"],"metadata":{"id":"aYHXwXH8b6Pj"}},{"cell_type":"code","metadata":{"id":"_WMkAtgCa03x"},"source":["# 정확도 계산 함수\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","# 시간 표시 함수\n","def format_time(elapsed):\n","    # 반올림\n","    elapsed_rounded = int(round((elapsed)))\n","    # hh:mm:ss으로 형태 변경\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2OoTZ9cwa4IJ"},"source":["# 재현을 위해 랜덤시드 고정\n","seed_val = 42\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# 그래디언트 초기화\n","model.zero_grad()\n","\n","# 에폭만큼 반복\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # 시작 시간 설정\n","    t0 = time.time()\n","\n","    # 로스 초기화\n","    total_loss = 0\n","\n","    # 훈련모드로 변경\n","    model.train()\n","        \n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for step, batch in enumerate(train_dataloader):\n","        # 경과 정보 표시\n","        if step % 500 == 0 and not step == 0:\n","            elapsed = format_time(time.time() - t0)\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        # Forward 수행                \n","        outputs = model(b_input_ids, \n","                        token_type_ids=None, \n","                        attention_mask=b_input_mask, \n","                        labels=b_labels)\n","        \n","        # 로스 구함\n","        loss = outputs[0]\n","\n","        # 총 로스 계산\n","        total_loss += loss.item()\n","\n","        # Backward 수행으로 그래디언트 계산\n","        loss.backward()\n","\n","        # 그래디언트 클리핑\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # 그래디언트를 통해 가중치 파라미터 업데이트\n","        optimizer.step()\n","\n","        # 스케줄러로 학습률 감소\n","        scheduler.step()\n","\n","        # 그래디언트 초기화\n","        model.zero_grad()\n","\n","    # 평균 로스 계산\n","    avg_train_loss = total_loss / len(train_dataloader)            \n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    #시작 시간 설정\n","    t0 = time.time()\n","\n","    # 평가모드로 변경\n","    model.eval()\n","\n","    # 변수 초기화\n","    eval_loss, eval_accuracy = 0, 0\n","    nb_eval_steps, nb_eval_examples = 0, 0\n","\n","    # 데이터로더에서 배치만큼 반복하여 가져옴\n","    for batch in validation_dataloader:\n","        # 배치를 GPU에 넣음\n","        batch = tuple(t.to(device) for t in batch)\n","        \n","        # 배치에서 데이터 추출\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        # 그래디언트 계산 안함\n","        with torch.no_grad():     \n","            # Forward 수행\n","            outputs = model(b_input_ids, \n","                            token_type_ids=None, \n","                            attention_mask=b_input_mask)\n","        \n","        # 로스 구함\n","        logits = outputs[0]\n","\n","        # CPU로 데이터 이동\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","        \n","        # 출력 로짓과 라벨을 비교하여 정확도 계산\n","        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n","        eval_accuracy += tmp_eval_accuracy\n","        nb_eval_steps += 1\n","\n","    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n","    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n","\n","print(\"\")\n","print(\"Training complete!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GOzpzoszbDqd"},"source":["test = pd.read_excel('/content/drive/MyDrive/데캡디/감성대화/Training/validation.xlsx')"],"execution_count":null,"outputs":[]}]}